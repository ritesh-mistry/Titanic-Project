# -*- coding: utf-8 -*-
"""titanic project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MQT40AIrAxsVcw_WVoRMvCPxCwxv54eZ
"""

# Step 1: Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Step 1: Upload kaggle.json
from google.colab import files
files.upload()

# Step 2: Set up Kaggle
!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Step 3: Install Kaggle API
!pip install kaggle

# Step 4: Download the Titanic dataset
!kaggle competitions download -c titanic

# Step 5: Extract the dataset
!unzip titanic.zip -d titanic_data

# Step 6: Load the dataset
import pandas as pd
train = pd.read_csv('titanic_data/train.csv')
print(train.head())

# Step 2: Load the dataset
# Ensure you have downloaded the Titanic dataset from Kaggle and placed it in the same directory
test = pd.read_csv('titanic_data/test.csv')

train.head()

test.head()

# Step 3: Exploratory Data Analysis (EDA)
print(train.head())

print(train.info())

print(train.describe())

# Check for missing values
print(train.isnull().sum())

# Visualize missing data
sns.heatmap(train.isnull(), cbar=False, cmap="viridis")
plt.title("Missing Data in Training Set")
plt.show()

# Visualize survival rates based on features
sns.countplot(x="Survived", data=train)
plt.title("Survival Distribution")
plt.show()

sns.countplot(x="Pclass", hue="Survived", data=train)
plt.title("Survival Rate by Passenger Class")
plt.show()

sns.countplot(x="Sex", hue="Survived", data=train)
plt.title("Survival Rate by Gender")
plt.show()

# Step 4: Data Preprocessing
# Fill missing Age values with the median age
train['Age'].fillna(train['Age'].median(), inplace=True)
test['Age'].fillna(test['Age'].median(), inplace=True)

# Fill missing Embarked values with the most common port
train['Embarked'].fillna(train['Embarked'].mode()[0], inplace=True)

# Fill missing Fare values in the test set
test['Fare'].fillna(test['Fare'].median(), inplace=True)

# Drop the Cabin column (too many missing values)
train.drop(columns=['Cabin'], inplace=True)
test.drop(columns=['Cabin'], inplace=True)

# Convert categorical variables into numerical
train = pd.get_dummies(train, columns=['Sex', 'Embarked'], drop_first=True)
test = pd.get_dummies(test, columns=['Sex', 'Embarked'], drop_first=True)

# Drop unnecessary columns
train.drop(columns=['PassengerId', 'Name', 'Ticket'], inplace=True)
test.drop(columns=['PassengerId', 'Name', 'Ticket'], inplace=True)

# Step 5: Model Building
X = train.drop("Survived", axis=1)
y = train["Survived"]

# Split the data into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a Random Forest Classifier
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

# Step 6: Evaluation
# Predict on the validation set
y_pred = model.predict(X_val)

# Evaluate the model
accuracy = accuracy_score(y_val, y_pred)
print(f"Validation Accuracy: {accuracy:.2f}")

print("Confusion Matrix:")
print(confusion_matrix(y_val, y_pred))

print("Classification Report:")
print(classification_report(y_val, y_pred))

# Step 7: Make predictions on the test set
test_predictions = model.predict(test)

# Save predictions to a CSV file
output = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': test_predictions})
output.to_csv('submission.csv', index=False)
print("Submission file created.")

output = pd.DataFrame({'Survived': test_predictions})
output.to_csv('submission.csv', index=False)
print("Submission file created.")

